{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot classification sur un texte français\n",
    "\n",
    "#### Objectif\n",
    "L'objectif de la classification zero-shot est de classer des textes selon des catégories définies à l'exécution et non pas à l'entraînement.\n",
    "\n",
    "#### Méthode\n",
    "La première étape consiste à charger un modèle de réseaux de neurones. En utilisant l'API de huggingface, si le modèle n'a pas déjà été téléchargé, il le sera automatiquement, donc assurez-vous d'avoir une connexion Internet.\n",
    "\n",
    "Dans cette section, nous allons utiliser l'objet pipeline afin que le pré et post-traitement des réponses soient gérées automatiquement.\n",
    "Les différents modèles compatibles peuvent être retrouvés sur le site de Huggingface [https://huggingface.co/models?pipeline_tag=zero-shot-classification](https://huggingface.co/models?pipeline_tag=zero-shot-classification)\n",
    "\n",
    "Vous pouvez retrouver toutes les instructions d'utilisation de chaque modèle sur leur page dédiée. Par exemple, pour le modèle utilisé ci-dessous: [https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli](https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-mnli-xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données de test\n",
    "Pour un premier test, les données à indiquer sont:\n",
    "- Une chaîne de caractère à classifier. Avec le modèle proposé, le texte peut être proposé en 16 différentes langue dont l'anglais et le français\n",
    "- Une liste de chaîne de caractère correspondant aux classes. Vous pouvez les modifier pour tester les aptitudes et les limites du modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = \"La classification zero-shot est une sujet de deep learning ne nécessite pas une connaissance préalable des classes utilisées.\"\n",
    "candidate_labels = [\"politique\", \"économie\",  \"littérature\", \"technologies\"]\n",
    "\n",
    "#sequence_to_classify = \"Zero-shot classification is a deep learning classfication topic, where methods do not need to know the classes before inference. \"\n",
    "#candidate_labels = [\"politics\", \"economics\",  \"litterature\", \"technology\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exécutions\n",
    "Vous pouvez ensuite exécuter le pipeline pour en voir les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'La classification zero-shot est une sujet de deep learning ne nécessite pas une connaissance préalable des classes utilisées.', 'labels': ['technologies', 'politique', 'littérature', 'économie'], 'scores': [0.34595373272895813, 0.28582847118377686, 0.23987437784671783, 0.12834341824054718]}\n"
     ]
    }
   ],
   "source": [
    "output = classifier(sequence_to_classify, candidate_labels, multi_label=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résultats\n",
    "Ce classifieur renvoie un dictionnaire comprenant ces informations:\n",
    "- sequence: La chaîne de caractère donnée en entrée\n",
    "- labels: Les différentes classes proposées. L'ordre est à retenir car c'est cet ordre auquel correspond les scores.\n",
    "- scores: Les scores par classe. Les scores s'additionnent à 1, sauf si l'option multi_tabel est à true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultats de la classification:\n",
      "Phrase: La classification zero-shot est une sujet de deep learning ne nécessite pas une connaissance préalable des classes utilisées.\n",
      "Scores:\n",
      "technologies -> 0.34595373272895813\n",
      "politique -> 0.28582847118377686\n",
      "littérature -> 0.23987437784671783\n",
      "économie -> 0.12834341824054718\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultats de la classification:\")\n",
    "print(\"Phrase:\", output[\"sequence\"])\n",
    "print(\"Scores:\")\n",
    "n_classes = len(output[\"labels\"])\n",
    "for k in range(n_classes):\n",
    "    print(output[\"labels\"][k],\"->\",output[\"scores\"][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Évaluation via un dataset\n",
    "Avec la libraire datasets, également liée à Huggingface, il est possible de télécharger et d'utiliser différents jeux de données. Pour les plus gros, dédiés à l'entraînement ou au fine-tuning de réseaux de neurones, les élements peuvent être séparés en catégorie: \"training\", \"validation\" et \"test\". \n",
    "\n",
    "Dans le cas du jeu de données dans ce notebook, il s'agit uniquement d'un jeu de test, il n'y a donc que la sous-partie \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "{'label': 'Employment', 'text': \"Executive agrees to be employed with the Company, and the Company agrees to employ Executive, during the Term and on the terms and conditions set forth in this Agreement. Executive agrees during the term of this Agreement to devote substantially all of Executive’s business time, efforts, skills and abilities to the performance of Executive’s duties to the Company and to the furtherance of the Company's business.\", 'options': ['Employment', 'Indemnifications', 'Waivers', 'Intellectual Property']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"AdaptLLM/law_knowledge_prob\")\n",
    "\n",
    "data = ds['test']\n",
    "print(len(data))\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous remarquez que chaque élément de ce dataset contient plusieurs termes:\n",
    "- label: La classification attendue\n",
    "- text: La phrase à classifier\n",
    "- options: Les classes possible. La classification attendue, ainsi que des classifications fausses en font partie.\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "\n",
    "La première étape consiste à créer les prédictions de notre réseau. Dans la section ci-dessous nous utilisons une quantité limitée de données pour éviter des temps de calcul trop longs (10 éléments = 10-15 secondes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "references = ds['test']['label'][:n]\n",
    "predictions = []\n",
    "\n",
    "for k in range(n):\n",
    "    results = classifier(ds['test']['text'][k], ds['test']['options'][k])\n",
    "    predictions.append(results['labels'][0])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les prédictions et resultats récupérés, on peut les comparer afin d'avoir la proportion de bonnes réponses.\n",
    "\n",
    "Pour évaluer la qualité des résultats, plusieurs métriques existent selon le cas d'application. Pour cet exemple en classification zero-shot, la métrique d'évaluation que nous allons utiliser est la proporition de données classées correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exac' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m metric \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact_match\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m exact_match \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mcompute(references\u001b[38;5;241m=\u001b[39mreferences,predictions\u001b[38;5;241m=\u001b[39mpredictions)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mexac\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(exact_match[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact_match\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exac' is not defined"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load('exact_match')\n",
    "exact_match = metric.compute(references=references,predictions=predictions)\n",
    "print(exact_match)\n",
    "print(exact_match['exact_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
